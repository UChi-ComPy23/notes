{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory and Performance\n",
    "\n",
    "This section will cover memory layout in numpy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with an example - summing up rows or columns of an array.  The computational complexity of each function is exactly the same: $n$ additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "x = np.random.rand(n, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.82 µs ± 37.5 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 µs ± 818 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[:,0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note there is a noticable difference in how long it takes the loop to run.  Summing over rows is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.2 µs ± 397 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29 µs ± 502 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x[:,0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now summing over columns is faster.\n",
    "\n",
    "Why did this `order` flag matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Memory\n",
    "\n",
    "There are several places you may have data stored on your computer:\n",
    "1. Hard Drive/SSD O(TB)\n",
    "2. Random Access Memory O(10GB)\n",
    "3. L3 Cache O(10MB)\n",
    "4. L2 Cache O(100KB)\n",
    "5. L1 Cache O(64KB)\n",
    "6. CPU (registers)\n",
    "\n",
    "At the top of the list, we have a lot of storage, but it takes longer to access data (in terms of clock cycles).\n",
    "As we go down the list, the amount of available storage decreases, but we are able to access data much faster.\n",
    "We can access CPU registers in 1 clock cycle, but we can only hold a small number (e.g. 8) 64-bit floats.\n",
    "\n",
    "When you loop over an array, memory is copied from one location to the next down the list.  Usually you're going to start in RAM, where you generate data or load from disk.\n",
    "\n",
    "Every element in an array has a unique address (in RAM) - for a 64-bit architecture, every address is for a 64-bit (8-byte) word.  This will hold exactly one 64-bit double.\n",
    "\n",
    "Typically, arrays are stored in contiguous blocks of memory, meaning that the first element is stored at some address `a`, the second element is stored at the address `a+1` (64-bits later), and generally the ith element is stored at address `a+i`\n",
    "\n",
    "An array will contain a pointer to the start of the data (i.e. the address of the start of the array), and when you get an element of an array `x[i]`, you first look up the starting address `a`, and then look up the data in address `a+i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "<memory at 0x7fa9b3cefe80>\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(5)\n",
    "print(x)\n",
    "a = x.data # address of start of array\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note `0x40 = 64`\n",
    "\n",
    "|address|data|\n",
    "|:-:|:-:|\n",
    "|0x00| 0|\n",
    "|0x40| 1|\n",
    "|0x80| 2|\n",
    "|0xb0| 3|\n",
    "\n",
    "When you access some element of memory for a computation in the CPU, you don't just move that one address to cache, but a whole block of memory around that address.  That way when you look at the next address, it is pre-loaded in cache, and you will be able to access the data in that address much faster.  \n",
    "\n",
    "When an address you want to access is not loaded in cache, it is called a **cache miss** and it takes extra time to move that memory to cache and then to the CPU.  Code that minimizes the number of cache misses will be much faster than code that maximizes the number of cache misses.\n",
    "\n",
    "This is why looping over an array in memory order is much faster than looping in a different order.\n",
    "\n",
    "## Two-dimensional arrays\n",
    "\n",
    "Everything we've said so far is fairly straightforward for 1-dimensional arrays.  What about multi-dimensional arrays?\n",
    "\n",
    "We'll consider 2-dimensional arrays, but these ideas generalize to higher dimensions.\n",
    "\n",
    "Two-dimensional arrays have two indices, so at most one of them can be used to access adjacent addresses in memory.  If we store rows (1st index) of a 2-dimensional array in contiguous memory, we say the array is in **row major** format.  If we store columns (2nd index) of a 2-dimensional array in contiguous memory, we say the array is in **column major** format.\n",
    "\n",
    "C/C++ and Python store multi-dimensional arrays in **row major** format\n",
    "\n",
    "Fortran, Matlab, R, and Julia store multi-dimensional arrays in **column major** format\n",
    "\n",
    "Because numerical libraries are often written in C/C++ or Fortran, there will be no end to having to worry about row vs. column major formats in scientific computing.  However, for a variety of reasons column major is considered the default (in particular, BLAS is column-major).\n",
    "\n",
    "Numpy supports both row and column major format, but is row-major by default.  You can see this by accessing the `flags` field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : False\n",
       "  OWNDATA : True\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(3,3)\n",
    "x.flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C_CONTIGUOUS` (C default) is refering to row-major format.  `F_CONTIGUOUS` (fortran default) is referring to column-major.\n",
    "\n",
    "The `order` flag in array creation can be used to manupulate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row major:\n",
      "  C_CONTIGUOUS : True\n",
      "  F_CONTIGUOUS : False\n",
      "  OWNDATA : True\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  WRITEBACKIFCOPY : False\n",
      "\n",
      "Column major:\n",
      "  C_CONTIGUOUS : False\n",
      "  F_CONTIGUOUS : True\n",
      "  OWNDATA : True\n",
      "  WRITEABLE : True\n",
      "  ALIGNED : True\n",
      "  WRITEBACKIFCOPY : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Row major:\")\n",
    "x = np.array(np.random.rand(3,3), order='C')\n",
    "print(x.flags)\n",
    "\n",
    "print(\"Column major:\")\n",
    "x = np.array(np.random.rand(3,3), order='F')\n",
    "print(x.flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Are 1-dimensional arrays row or column major?  Look at the `flags` field of a numpy array.\n",
    "2. Go back to our example of computing the sum of rows and columns.  Can you explain the timing differences now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : True\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : True\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(5)\n",
    "x.flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba Examples\n",
    "\n",
    "Memory storage has implications for how you may wish to loop over arrays in general.  We'll use Numba to demonstrate this, because naive Python loops have too much overhead to see a big difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True) # throws error if not able to compile\n",
    "def numba_matvec_row(A, x):\n",
    "    \"\"\"\n",
    "    naive matrix-vector multiplication implementation\n",
    "    \n",
    "    Loops over rows in outer loop\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    y = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            y[i] = y[i] + A[i,j] * x[j]\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "@jit(nopython=True) # throws error if not able to compile\n",
    "def numba_matvec_col(A, x):\n",
    "    \"\"\"\n",
    "    naive matrix-vector multiplication implementation\n",
    "    \n",
    "    Loops over columns in outer loop\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    y = np.zeros(m)\n",
    "    for j in range(n):\n",
    "        for i in range(m):\n",
    "            y[i] = y[i] + A[i,j] * x[j]\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4000\n",
    "n = 4000\n",
    "A = np.array(np.random.randn(m,n), order='C')\n",
    "x = np.random.randn(n)\n",
    "\n",
    "# precompile\n",
    "y = numba_matvec_row(A, x)\n",
    "y = numba_matvec_col(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.1 ms ± 649 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = numba_matvec_row(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 ms ± 4.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = numba_matvec_col(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4000\n",
    "n = 4000\n",
    "A = np.array(np.random.randn(m,n), order='F')\n",
    "x = np.random.randn(n)\n",
    "\n",
    "# precompile\n",
    "y = numba_matvec_row(A, x)\n",
    "y = numba_matvec_col(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.7 ms ± 1.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = numba_matvec_row(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.61 ms ± 627 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = numba_matvec_col(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, we're seeing a bigger difference when `A` is in column major order.  Let's see if we can improve the row major function.  We'll use NumPy's `dot` function to take explicit advantage of the contiguous row layout.  (Note that Numba is generally compatible with built-in NumPy functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True) # throws error if not able to compile\n",
    "def numba_matvec_row2(A, x):\n",
    "    \"\"\"\n",
    "    naive matrix-vector multiplication implementation\n",
    "    \n",
    "    Loops over rows in outer loop\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    y = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        y[i] = np.dot(A[i], x) # takes explicit advantage of the contigous row layout\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4000\n",
    "n = 4000\n",
    "A = np.array(np.random.randn(m,n), order='C')\n",
    "x = np.random.randn(n)\n",
    "\n",
    "# precompile\n",
    "y = numba_matvec_row(A, x)\n",
    "y = numba_matvec_row2(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.8 ms ± 3.25 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = numba_matvec_row(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.93 ms ± 986 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = numba_matvec_row2(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we finally see a speedup.  Let's compare to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 ms ± 722 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = np.matmul(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba still isn't quite as fast.  Let's see if we can use some parallelism to help us out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import prange\n",
    "\n",
    "@jit(nopython=True, parallel=True) # throws error if not able to compile\n",
    "def numba_matvec_row3(A, x):\n",
    "    \"\"\"\n",
    "    naive matrix-vector multiplication implementation\n",
    "    \n",
    "    Loops over rows in outer loop\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    y = np.zeros(m)\n",
    "    for i in prange(m):\n",
    "        y[i] = np.dot(A[i], x) # takes explicit advantage of the contigous row layout\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4000\n",
    "n = 4000\n",
    "A = np.array(np.random.randn(m,n), order='C')\n",
    "x = np.random.randn(n)\n",
    "\n",
    "# precompile\n",
    "y = numba_matvec_row3(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.58 ms ± 422 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = numba_matvec_row3(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.31 ms ± 759 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = np.matmul(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that looping over the matrix `A` in different orders can make a noticeable difference.  However, even using Numba, it is hard to beat NumPy's built-in capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pycourse_test)",
   "language": "python",
   "name": "pycourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
